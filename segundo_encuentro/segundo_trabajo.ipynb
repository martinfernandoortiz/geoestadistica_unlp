{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2055ba2-3156-4879-bfe4-45c1b30c4d9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# *Manejo de muestras de datos*\n",
    "## Repaso de conceptos – Práctica 2\n",
    "## Geoestadı́stica -Maestrı́a en Geomática UNLP\n",
    "\n",
    "En un estudio global en todo el paı́s se registraron una serie de medi-\n",
    "ciones meteorológicas mensuales durante el perı́odo 1981-2010. Con el\n",
    "fin de caracterizar tendencias climatológicas se generó un base de datos.\n",
    "En principio, como primera medida, se necesita identificar las principales\n",
    "caracterı́sticas estadı́sticas de este set de datos con el fin de tener un re-\n",
    "sultado rápido pero consistente. De esta manera se decidió que lo más\n",
    "conveniente serı́a identificar en una tabla, por variable meteorológica, lo\n",
    "siguiente:\n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd526576-bf59-4bb1-b9bf-d55e28b4d40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################################################################\n",
    "#\n",
    "#   - Importacion de librerias\n",
    "#   - Asignaciòn de alias\n",
    "#\n",
    "####################################################################\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "#import geopandas as gpd\n",
    "# Preprocesado y modelado\n",
    "# ==============================================================================\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#https://towardsdatascience.com/detecting-and-treating-outliers-in-python-part-3-dcb54abaf7b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8795f4fd-92d6-4220-8a2a-a3d8e3f0618c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "    \n",
    "path = \"datasets/\"    \n",
    "archivo = \"SMN_estaciones_medias_mensuales_1989_2010.xls\"\n",
    "df = pd.read_excel(archivo)\n",
    "df.replace(\"S/D\", np.NaN, inplace = True) #reemplazar los \"S/D\"\n",
    "\n",
    "#df['Temperatura_minima_(C)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7909a44e-a852-4d97-82da-0fbd6014241f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 840 entries, 0 to 839\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Unnamed: 0.1                           840 non-null    int64  \n",
      " 1   Unnamed: 0                             840 non-null    int64  \n",
      " 2   Estacion                               840 non-null    object \n",
      " 3   mes                                    840 non-null    object \n",
      " 4   lat                                    840 non-null    float64\n",
      " 5   long                                   840 non-null    float64\n",
      " 6   Altura_(m)                             840 non-null    int64  \n",
      " 7   Numero                                 840 non-null    int64  \n",
      " 8   Temperatura_(C)                        838 non-null    float64\n",
      " 9   Temperatura_maxima_(C)                 840 non-null    float64\n",
      " 10  Temperatura_minima_(C)                 818 non-null    float64\n",
      " 11  Humedad_relativa_(%)                   812 non-null    float64\n",
      " 12  Velocidad_del_Viento_(km/h)            708 non-null    float64\n",
      " 13  Nubosidad_total_(octavos)              826 non-null    float64\n",
      " 14  Precipitacion_(mm)                     807 non-null    float64\n",
      " 15  Frecuencia_dias_Precipitacion_>0.1_mm  807 non-null    float64\n",
      "dtypes: float64(10), int64(4), object(2)\n",
      "memory usage: 105.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#Finalmente vamos a utilizar ésta forma para cambiar el tipo de campo\n",
    "rango= np.r_[8:16]\n",
    "df[df.columns[rango]] = df[df.columns[rango]].astype(float)\n",
    "df.dtypes\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7fc13df0-2bb8-4000-95ec-4ae132058cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ver si reemplazamos outliers por na o por otra medida\n",
    "def f(row):\n",
    "    if (row[colname] < lower_lim) | (row[colname] > upper_lim):\n",
    "        val = np.NaN\n",
    "    else:\n",
    "        val = row[colname]\n",
    "\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18aa1750-9725-4a24-80d4-06eb7a43abca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ver si reemplazamos outliers por percentil\n",
    "\n",
    "def f(row):\n",
    "    if row[colname] < lower_lim:\n",
    "        val = lower_lim\n",
    "    elif row[colname] > upper_lim:\n",
    "        val = upper_lim\n",
    "    else:\n",
    "        val = row[colname]\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "12329c00-395a-4333-9174-b061902e3be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outliers_df = pd.DataFrame()\n",
    "#type(estadisticos)\n",
    "rango= np.r_[8:15]\n",
    "\n",
    "for x in rango:\n",
    "    \n",
    "    colname = df.columns[x]\n",
    "   # print(colname)\n",
    "    Q1 = df[colname].quantile(0.25)\n",
    "    Q3 = df[colname].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_lim = Q1 - 1.5 * IQR\n",
    "    upper_lim = Q3 + 1.5 * IQR\n",
    "    df['outlier'] = df.apply(f, axis=1)\n",
    "    df[colname] = df['outlier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41c17ee8-b07c-4f50-b009-fb38b40f2b17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.265892420537897"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Temperatura_minima_(C)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "837d0722-161a-4ff3-bf7c-4cf092fb1ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Media de cada variable\n",
      "----------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1                               419.500000\n",
       "Unnamed: 0                                 425.157143\n",
       "lat                                        -31.455232\n",
       "long                                       -57.741740\n",
       "Altura_(m)                                 339.842857\n",
       "Numero                                   87500.842857\n",
       "Temperatura_(C)                             15.916527\n",
       "Temperatura_maxima_(C)                      22.513214\n",
       "Temperatura_minima_(C)                      10.265892\n",
       "Humedad_relativa_(%)                        68.123522\n",
       "Velocidad_del_Viento_(km/h)                 12.330862\n",
       "Nubosidad_total_(octavos)                    3.772881\n",
       "Precipitacion_(mm)                          69.334201\n",
       "Frecuencia_dias_Precipitacion_>0.1_mm        6.756877\n",
       "outlier                                     69.334201\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Media\n",
    "\n",
    "print('----------------------')\n",
    "print('Media de cada variable')\n",
    "print('----------------------')\n",
    "df.mean(axis=0, numeric_only = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d302825b-bf24-43c5-a9ba-bd2f747c0f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Varianza de cada variable\n",
      "-------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1                              58870.000000\n",
       "Unnamed: 0                                61420.690414\n",
       "lat                                          71.048752\n",
       "long                                        123.912890\n",
       "Altura_(m)                               241663.169556\n",
       "Numero                                   127838.120688\n",
       "Temperatura_(C)                              46.899090\n",
       "Temperatura_maxima_(C)                       50.681690\n",
       "Temperatura_minima_(C)                       44.106828\n",
       "Humedad_relativa_(%)                        112.403706\n",
       "Velocidad_del_Viento_(km/h)                  25.668831\n",
       "Nubosidad_total_(octavos)                     0.369615\n",
       "Precipitacion_(mm)                         2713.503122\n",
       "Frecuencia_dias_Precipitacion_>0.1_mm         7.635285\n",
       "outlier                                    2713.503122\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('-------------------------')\n",
    "print('Varianza de cada variable')\n",
    "print('-------------------------')\n",
    "df.var(axis=0) # Entrenamiento modelo PCA con escalado de los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccdc91a-b4d2-4b46-8405-e22d943daa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reemplazar NaN por estadistico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "812406da-619b-47d7-90ac-9ba8959f3463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 840 entries, 0 to 839\n",
      "Data columns (total 17 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   Unnamed: 0.1                           840 non-null    int64  \n",
      " 1   Unnamed: 0                             840 non-null    int64  \n",
      " 2   Estacion                               840 non-null    object \n",
      " 3   mes                                    840 non-null    object \n",
      " 4   lat                                    840 non-null    float64\n",
      " 5   long                                   840 non-null    float64\n",
      " 6   Altura_(m)                             840 non-null    int64  \n",
      " 7   Numero                                 840 non-null    int64  \n",
      " 8   Temperatura_(C)                        840 non-null    float64\n",
      " 9   Temperatura_maxima_(C)                 840 non-null    float64\n",
      " 10  Temperatura_minima_(C)                 840 non-null    float64\n",
      " 11  Humedad_relativa_(%)                   840 non-null    float64\n",
      " 12  Velocidad_del_Viento_(km/h)            840 non-null    float64\n",
      " 13  Nubosidad_total_(octavos)              840 non-null    float64\n",
      " 14  Precipitacion_(mm)                     840 non-null    float64\n",
      " 15  Frecuencia_dias_Precipitacion_>0.1_mm  807 non-null    float64\n",
      " 16  outlier                                807 non-null    float64\n",
      "dtypes: float64(11), int64(4), object(2)\n",
      "memory usage: 111.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a9084b73-430e-4cf8-b725-20c1b3b55f3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#type(estadisticos)\n",
    "rango= np.r_[8:15]\n",
    "\n",
    "for x in rango:\n",
    "    \n",
    "    colname = df.columns[x]\n",
    "   # print(colname)\n",
    "    mean1 = df[colname].mean()\n",
    "    df[colname] = df[colname].replace(np.nan, mean1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed22accb-be9f-46f2-8275-43224c1b34e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Entrenamiento modelo PCA con escalado de los datos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m      4\u001b[0m pca_pipe \u001b[38;5;241m=\u001b[39m make_pipeline(StandardScaler(), PCA())\n\u001b[0;32m----> 5\u001b[0m \u001b[43mpca_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Se extrae el modelo entrenado del pipeline\u001b[39;00m\n\u001b[1;32m      8\u001b[0m modelo_pca \u001b[38;5;241m=\u001b[39m pca_pipe\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpca\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:435\u001b[0m, in \u001b[0;36mPCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;124;03m    Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 435\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/decomposition/_pca.py:485\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA does not support sparse input. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTruncatedSVD for a possible alternative.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m     )\n\u001b[0;32m--> 485\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;66;03m# Handle n_components==None\u001b[39;00m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    918\u001b[0m         )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 921\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "\n",
    "df1 = df.iloc[:, np.r_[8:16]]\n",
    "# Entrenamiento modelo PCA con escalado de los datos\n",
    "# ==============================================================================\n",
    "pca_pipe = make_pipeline(StandardScaler(), PCA())\n",
    "pca_pipe.fit(df1)\n",
    "\n",
    "# Se extrae el modelo entrenado del pipeline\n",
    "modelo_pca = pca_pipe.named_steps['pca']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6239891-dc59-4da6-aa98-03ddeae92eb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d98c0-fef5-44ba-9328-1dd559035b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e78390-a358-4014-afa4-2e5f777f37a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ejemplo: df.Per  #  df.Per.values\n",
    "\n",
    "plt.boxplot(df.Per)\n",
    "#plt.hist()\n",
    "#plt.scatter()\n",
    "#plt.bar()\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39366b28-68ac-4b48-89a9-28b06daf8937",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
